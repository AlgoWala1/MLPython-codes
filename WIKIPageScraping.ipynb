{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMgTTH32M/fKmMru0WBo3jm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AlgoWala1/MLPython-codes/blob/main/WIKIPageScraping.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "XyC77_em-5EH"
      },
      "outputs": [],
      "source": [
        "from bs4 import BeautifulSoup\n",
        "import os\n",
        "import requests\n",
        "\n",
        "def Images(soup):\n",
        "  numbering = 1\n",
        "  os.chdir(\"/content/Images\")\n",
        "  images = soup.find_all('img')\n",
        "  for image in images:\n",
        "    #if image is not of the type //upload\n",
        "    if image['src'].find(\"upload\")==-1:\n",
        "      continue\n",
        "    #use the word after / as file name\n",
        "    imageLink = \"https:\" + image['src']\n",
        "    imageName = f'''Image{numbering}.jpg'''\n",
        "    imageFile = requests.get(imageLink,params = {'User-Agent':'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/126.0.0.0 Safari/537.36 Edg/126.0.0.0'})\n",
        "    with open(imageName,'wb') as img:\n",
        "      img.write(imageFile.content)\n",
        "    numbering+=1\n",
        "\n",
        "def Links(soup):\n",
        "  #extract all Links in a python file\n",
        "  links = soup.find_all(\"a\")\n",
        "  os.chdir(\"/content/Links\")\n",
        "  with open(\"Links.txt\",\"w\") as LinkFile:\n",
        "    for link in links:\n",
        "      try:\n",
        "        #find all sublinks\n",
        "       if link['href'].startswith('/wiki'):\n",
        "        linkName = \"https://en.wikipedia.org\" + link['href']\n",
        "        LinkFile.write(linkName + \"\\n\")\n",
        "      except KeyError as e:\n",
        "        continue\n",
        "\n",
        "\n",
        "webUrl = requests.get('https://en.wikipedia.org/wiki/Flower')\n",
        "soup = BeautifulSoup(webUrl.text,parser = 'html')\n",
        "content = soup.find(\"div\",class_='mw-content-ltr mw-parser-output')\n",
        "os.chdir(\"/content\")\n",
        "with open(\"Content.txt\",\"w\") as Text:\n",
        "  Text.write(content.text.strip())\n",
        "Images(soup)\n",
        "Links(soup)"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "uwiawudIAq51"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}